{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn as sk\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./BioCode for Machine Learning.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average similarity. One of the features used in Jeremy's original classifier\n",
    "avsim = df['avg_Similarity']\n",
    "#Classifications of species\n",
    "cls = df['Classification']\n",
    "#branch distance; also used by jeremy, apparently one of the better predictors\n",
    "bdist = df['Distance_of_Branch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression (one label at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.345294238261\n"
     ]
    }
   ],
   "source": [
    "#How many of the classifications are known\n",
    "print((cls.fillna(0) != 0).sum()/cls.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Samples where there are no NaNs\n",
    "valid_samples = np.array((cls.fillna(0) != 0) * (1 - bdist.isnull()) * (1 - avsim.isnull())).astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1684, 4877, 0.34529423826122618)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many samples are usable\n",
    "valid_samples.sum(), avsim.size, valid_samples.sum()/avsim.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning 'Indigenous' to 1, and others to 0\n",
    "cls_binary = (cls == 'Indigenous')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter\n",
    "avsim_valid, cls_valid, bdist_valid = avsim[valid_samples], cls_binary[valid_samples], bdist[valid_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test/train\n",
    "test_train_ratio = 0.9\n",
    "avs_train, avs_test, cls_train, cls_test, bdist_train, bdist_test = train_test_split(avsim_valid, cls_valid, bdist_valid, test_size=test_train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 1516)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just to get an idea of test/train sizes:\n",
    "avs_train.size, avs_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,ElasticNet,Lasso,LinearRegression\n",
    "from sklearn.metrics import zero_one_loss, mean_squared_error, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(avs_train), np.array(cls_train)]).T\n",
    "y = cls_train\n",
    "X_test = np.array([np.array(avs_test), np.array(cls_test)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14880952380952381, 0.16820580474934038)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure that class sizes are similar in test/train sets\n",
    "cls_train.sum()/cls_train.size, cls_test.sum()/cls_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 1.0\n",
      "Weights: [  1.51618023e-18   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#LinReg\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1 #Threshold\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seems like branch distance is a much better predictor than avg sim. this matches Jeremy's observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 1.0\n",
      "Weights: [[-0.02180076  4.76811675]]\n"
     ]
    }
   ],
   "source": [
    "#LogReg\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These predictions look impressive until you realize that it is possible to get 83% By just predicting 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.831794195251\n"
     ]
    }
   ],
   "source": [
    "print('Prediciton accuracy:', np.mean((cls_test == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What about other labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.839920948617\n",
      "Weights: [ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "clf = Lasso()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.839920948617\n",
      "Weights: [  8.37147108e-05   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "clf = ElasticNet()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25595238095238093, 0.29155672823218998)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning 'Invasive' to 1, and others to 0\n",
    "cls_binary = (cls == 'Invasive')*1\n",
    "avsim_valid, cls_valid, bdist_valid = avsim[valid_samples], cls_binary[valid_samples], bdist[valid_samples]\n",
    "#Split into test/train\n",
    "test_train_ratio = 0.9\n",
    "avs_train, avs_test, cls_train, cls_test, bdist_train, bdist_test = train_test_split(avsim_valid, cls_valid, bdist_valid, test_size=test_train_ratio)\n",
    "X = np.array([np.array(avs_train), np.array(cls_train)]).T\n",
    "y = cls_train\n",
    "X_test = np.array([np.array(avs_test), np.array(cls_test)]).T\n",
    "cls_train.sum()/cls_train.size, cls_test.sum()/cls_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 1.0\n",
      "Weights: [ -6.04994756e-19   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#LinReg\n",
    "clf = LinearRegression()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1 #Threshold\n",
    "#Prediction accuracy\n",
    "print('Prediction accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 1.0\n",
      "Weights: [[-0.0199216   5.07084628]]\n"
     ]
    }
   ],
   "source": [
    "#LogReg\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1\n",
    "#Prediction accuracy\n",
    "print('Prediction accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.708443271768\n"
     ]
    }
   ],
   "source": [
    "print('Prediction accuracy:', np.mean((cls_test == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52380952380952384, 0.54815303430079154)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning 'Introduced' to 1, and others to 0\n",
    "cls_binary = (cls == 'Introduced')*1\n",
    "avsim_valid, cls_valid, bdist_valid = avsim[valid_samples], cls_binary[valid_samples], bdist[valid_samples]\n",
    "#Split into test/train\n",
    "test_train_ratio = 0.9\n",
    "avs_train, avs_test, cls_train, cls_test, bdist_train, bdist_test = train_test_split(avsim_valid, cls_valid, bdist_valid, test_size=test_train_ratio)\n",
    "X = np.array([np.array(avs_train), np.array(cls_train)]).T\n",
    "y = cls_train\n",
    "X_test = np.array([np.array(avs_test), np.array(cls_test)]).T\n",
    "cls_train.sum()/cls_train.size, cls_test.sum()/cls_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 1.0\n",
      "Weights: [  2.14965583e-19   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#LinReg\n",
    "clf = LinearRegression()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1 #Threshold\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 1.0\n",
      "Weights: [[-0.01576545  5.31332309]]\n"
     ]
    }
   ],
   "source": [
    "#LogReg\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "prediction = (clf.predict(X_test) > 0.5)*1\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(cls_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.548153034301\n"
     ]
    }
   ],
   "source": [
    "print('Prediciton accuracy:', np.mean((cls_test == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In principle, one can train simple linear regression on 10% of data and get 100% accuracy. But note that we are only looking at results for ~1000 points. This is probably overfitting and we probably want a more principled approach that is robust to errors in sequencing and matching etc. Since the dataset already has information about those things, we should try to integrate it. Also, branch distance already includes a lot of preprocessing. Can we replicate its effectiveness, but with more robustness?\n",
    "\n",
    "Spoiler: Performance decreases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
